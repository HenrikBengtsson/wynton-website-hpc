# How to Cite

## Publication Acknowledgment

If you'd like to acknowledge Wynton in your publication, you are welcome to use this sample verbiage:

> Portions of this work were performed on the Wynton HPC Co-Op
> cluster, which is supported by UCSF research faculty and UCSF
> institutional funds.  The authors wish to thank the UCSF Wynton team
> for their ongoing technical support of the Wynton environment.


## Grant Applications

Below are a few examples on how to give details on the {{< meta cluster.name >}} environment in a grant application.  _The node, CPU, and GPU core counts are updated on a regular basis._

### Example 1

> {{< meta cluster.name >}} is a distributed high-performance computing cluster with nodes
> in many different data centers on the UCSF campus.  All {{< meta cluster.name >}} sites are
> connected by multiple 40 Gbps network connections.  {{< meta cluster.name >}} currently
> contains 482 nodes with over
> 17496 CPU cores.
> RAM in the nodes ranges from 48 to
> 1512 GiB with an average RAM-to-core ratio of over 10 GiB.
> There are also 61 nodes containing a total of
> 235 GPUs.
> Storage is provided by a parallel filesystem providing 400 TB of mirrored
> home space and 500 TB of global scratch space.
>
> {{< meta cluster.nickname >}} is shared by many research groups at UCSF.  Load balancing on the
> cluster is achieved through SGE (originally Sun Grid Engine). The
> computing power of the cluster guaranteed to any given research group is
> directly proportional to the funds that the group contributed to the
> cluster. The balance of the computing power not used by the contributors
> is available to other registered groups (including other contributors) on
> a first-come, first-served basis.


### Example 2

> {{< meta cluster.name >}} is a computational research cluster shared by investigators at
> UCSF.  The cluster is run as a co-op, with access for all and priority
> given to those who have contributed funds or hardware.  Support is
> also provided by UCSF Research IT.  The cluster currently consists of
> 482 nodes with 17496 cores.
> Each node has at least 48 GiB of RAM and
> total home storage is 770 TiB.
